{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenoiserBlancheF.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqidURKGo2qr",
        "colab_type": "text"
      },
      "source": [
        "# Import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho6Y3eeUoyDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from IPython.display import display, Image\n",
        "\n",
        "import pathlib\n",
        "import glob\n",
        "import pickle\n",
        "from imutils import paths\n",
        "import cv2\n",
        "#import tensorflow_datasets as tfds\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Dropout,merge,Reshape, Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import TensorBoard\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5JSuT6HpHJV",
        "colab_type": "text"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BnEUAHdzNIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://data.csail.mit.edu/places/places365/val_large.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuyp3MV-6ARX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"val_large.tar\")\n",
        "tar.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QiKVDn9pJoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\n",
        "\n",
        "!mkdir div2k\n",
        "!unzip -q DIV2K_train_HR.zip -d div2k\n",
        "!unzip -q DIV2K_valid_HR.zip -d div2k\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ng4PeGppbIV",
        "colab_type": "text"
      },
      "source": [
        "## train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbDeQ1hIxC1n",
        "colab_type": "text"
      },
      "source": [
        "### data from the div2k dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW5cbN8MpW4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " imgPaths = list(paths.list_images(r\"./div2k/DIV2K_train_HR/\"))\n",
        " print(imgPaths)\n",
        " print(len(imgPaths))\n",
        " photosPaths = list(glob.glob('./div2k/DIV2K_train_HR/*.png'))\n",
        " print(len(photosPaths))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EepBWFuJw_By",
        "colab_type": "text"
      },
      "source": [
        "### data from the Places dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOHLYTcb7zZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " photosPaths1 = list(glob.glob('./val_large/*.jpg'))\n",
        " print(len(photosPaths1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEZ-TJx8pci2",
        "colab_type": "text"
      },
      "source": [
        "## valid data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJGAEBy4pX0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " imgPaths2 = list(paths.list_images(r\"./div2k/DIV2K_valid_HR/\"))\n",
        " print(imgPaths2)\n",
        " print(len(imgPaths2))\n",
        " photosPaths2 = list(glob.glob('./div2k/DIV2K_valid_HR/*.png'))\n",
        " print(len(photosPaths2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En389lWspkXd",
        "colab_type": "text"
      },
      "source": [
        "## display 2 images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns_jCMUGpnd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#display 2 images\n",
        "sample_images = glob.glob('./div2k/DIV2K_train_HR/*.png')[:2]\n",
        "for file_path in sample_images:\n",
        "  display(Image(file_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXW3aGQ_p3it",
        "colab_type": "text"
      },
      "source": [
        "# Process the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zDpQaqorLvx",
        "colab_type": "text"
      },
      "source": [
        "## Photos without noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt6l07WvxMtv",
        "colab_type": "text"
      },
      "source": [
        "### Data from the div2k dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GPD11Mzp6Un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = []\n",
        "for imgPath in photosPaths: \n",
        "   img = cv2.imread(imgPath, cv2.IMREAD_COLOR)\n",
        "   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "   img = cv2.resize(img,(200,200))\n",
        "   img = np.asarray(img)\n",
        "   img = img.astype(np.float32)\n",
        "   img= img/255.0\n",
        "   data_train.append(img)\n",
        "data_train=np.array(data_train)\n",
        "#print(data[0])\n",
        "print(len(data_train))\n",
        "print(data_train.shape)\n",
        "\n",
        "data_valid = []\n",
        "for imgPath in photosPaths2: \n",
        "   img = cv2.imread(imgPath, cv2.IMREAD_COLOR)\n",
        "   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "   img = cv2.resize(img,(200,200))\n",
        "   img = np.asarray(img)\n",
        "   img = img.astype(np.float32)\n",
        "   img= img/255.0\n",
        "   data_valid.append(img)\n",
        "data_valid=np.array(data_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej4gDCNzxJXQ",
        "colab_type": "text"
      },
      "source": [
        "### Data from the places dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYU93GQKceAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train2 = []\n",
        "# not enough ram to use all the images...\n",
        "for i in range (3000): \n",
        "   img = cv2.imread(photosPaths1[i], cv2.IMREAD_COLOR)\n",
        "   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "   img = cv2.resize(img,(200,200))\n",
        "   img = np.asarray(img)\n",
        "   img = img.astype(np.float32)\n",
        "   img= img/255.0\n",
        "   data_train2.append(img)\n",
        "data_train2=np.array(data_train2)\n",
        "\n",
        "data_valid2 = []\n",
        "for i in range (3000): \n",
        "   img = cv2.imread(photosPaths1[i+3001], cv2.IMREAD_COLOR)\n",
        "   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "   img = cv2.resize(img,(200,200))\n",
        "   img = np.asarray(img)\n",
        "   img = img.astype(np.float32)\n",
        "   img= img/255.0\n",
        "   data_valid2.append(img)\n",
        "data_valid2=np.array(data_valid2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkqHGS-MrP7W",
        "colab_type": "text"
      },
      "source": [
        "## Photos with noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scsmt-vwxUTm",
        "colab_type": "text"
      },
      "source": [
        "### Data from the div2k dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSN7_0lRrSce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_factor = 0.2\n",
        "data_train_noise = data_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data_train.shape)\n",
        "data_valid_noise = data_valid + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data_valid.shape)\n",
        "data_train_noise = np.clip(data_train_noise, 0., 1.)\n",
        "data_valid_noise = np.clip(data_valid_noise, 0., 1.)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWLK_bitrsDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"max : \",np.max(data_train))\n",
        "print(\"min : \",np.min(data_train))\n",
        "print(\"max : \",np.max(data_valid))\n",
        "print(\"min : \",np.min(data_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7tuoEP6xTX4",
        "colab_type": "text"
      },
      "source": [
        "### Data from the places dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzCkB_W9dW_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_factor = 0.2\n",
        "data_train2_noise = data_train2 + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data_train2.shape)\n",
        "data_valid2_noise = data_valid2 + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data_valid2.shape)\n",
        "data_train2_noise = np.clip(data_train2_noise, 0., 1.)\n",
        "data_valid2_noise = np.clip(data_valid2_noise, 0., 1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxX8o20mrnj8",
        "colab_type": "text"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaLk_lkJsCT6",
        "colab_type": "text"
      },
      "source": [
        "##Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PfbL5pGsSS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 200\n",
        "epochs = 20\n",
        "input_img = Input(shape = (200, 200, 3))\n",
        "\n",
        "def autoencoder(input_img):\n",
        "    #encoder\n",
        "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(c1)\n",
        "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(c2)\n",
        "    encoded = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "\n",
        "    #decoder\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
        "    up1 = UpSampling2D((2,2))(c4)\n",
        "    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
        "    up2 = UpSampling2D((2,2))(c5)\n",
        "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(up2)\n",
        "    return decoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-Ddg8zYshKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder = Model(input_img, autoencoder(input_img))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dZUuJ-FsJZP",
        "colab_type": "text"
      },
      "source": [
        "## Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5EdZ4rnsfKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(loss='mean_squared_error', optimizer = tf.keras.optimizers.RMSprop())\n",
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR2RtG72stax",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEdp36I0xaVy",
        "colab_type": "text"
      },
      "source": [
        "### Data from the div2k dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpDfXbUiwHN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder_train = autoencoder.fit(data_train_noise, data_train, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(data_valid_noise,data_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfEO2dmgxcco",
        "colab_type": "text"
      },
      "source": [
        "### Data from the places dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7GM_TjAsrzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder_train = autoencoder.fit(data_train2_noise, data_train2, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(data_valid2_noise,data_valid2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9mgclzOs9tw",
        "colab_type": "text"
      },
      "source": [
        "# Test the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ85s40ZtK6j",
        "colab_type": "text"
      },
      "source": [
        "## Plot the training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsWUWcs6tH4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = autoencoder_train.history['loss']\n",
        "val_loss = autoencoder_train.history['val_loss']\n",
        "epochs = range(epochs)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVC6XEzDti_A",
        "colab_type": "text"
      },
      "source": [
        "## Show some result images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcxrHk_YxstR",
        "colab_type": "text"
      },
      "source": [
        "### decoding the validation images just to see how it looked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8505AtXjxpgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgs = autoencoder.predict(data_valid_noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VoOCgkStl7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 5\n",
        "plt.figure(figsize=(15,8))\n",
        "for i in range(n):\n",
        "    #disp original\n",
        "    ax = plt.subplot(2, n, i+1)\n",
        "    plt.imshow(data_valid_noise[i].reshape(200,200,3))\n",
        "    plt.plasma()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i+n+1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(200,200,3))\n",
        "    plt.plasma()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdbPVNagxx1O",
        "colab_type": "text"
      },
      "source": [
        "### Using images from the places dataset to test the model trained wth div2k images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6xthkdSGqeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_test = []\n",
        "for i in range (20): \n",
        "   img = cv2.imread(photosPaths1[i], cv2.IMREAD_COLOR)\n",
        "   img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "   img = cv2.resize(img,(200,200))\n",
        "   img = np.asarray(img)\n",
        "   img = img.astype(np.float32)\n",
        "   img= img/255.0\n",
        "   data_test.append(img)\n",
        "data_test=np.array(data_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAd3vMocG25m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_factor = 0.2\n",
        "data_test_noise = data_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data_test.shape)\n",
        "data_test_noise = np.clip(data_test_noise, 0., 1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_pklbf1b2Nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgs = autoencoder.predict(data_test_noise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN7w354ib72Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 5\n",
        "plt.figure(figsize=(15,8))\n",
        "for i in range(n):\n",
        "    #disp original\n",
        "    ax = plt.subplot(2, n, i+1)\n",
        "    plt.imshow(data_test[i].reshape(200,200,3))\n",
        "    plt.plasma()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i+n+1)\n",
        "    plt.imshow(decoded_imgs[i].reshape(200,200,3))\n",
        "    plt.plasma()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}