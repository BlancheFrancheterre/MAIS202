# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HcEFTu1Y86wI-dY_BuQLqs52blkzgqse

###### FINAL PROJECT DELIVERABLE 2

We will follow the steps:


*   Analzyze the dataset
* Prepare the dataset
* Create the model
* compile the model
* fit the model
* evaluate the model

## Import statements
"""

from __future__ import absolute_import, division, print_function, unicode_literals
import numpy as np
import tensorflow as tf
import IPython.display as display
from PIL import Image
import pathlib
import os
import glob
from imutils import paths
import cv2
import tensorflow_datasets as tfds
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Dropout
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import random
#from scipy.misc import imresize

"""## Load the data"""

#https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip

data_dir = tf.keras.utils.get_file(origin='https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip', fname='photos',   extract=True )
!wget -O a3_face_dataset.tar.gz https://www.dropbox.com/s/4nmsiafyvw0o5fx/a3_face_dataset.tar.gz?dl=0
!tar xzf a3_face_dataset.tar.gz
!ls

"""## Put the images into a list or array"""

#img= np.array(data_dir)
# data_dir = pathlib.Path(data_dir)
imgPaths = list(paths.list_images(data_dir))
photosPaths2 = list(glob.glob('a3_face_dataset/*.jpg'))
#random.shuffle(imgPaths)
#images=glob.glob('./photos/*.png')

#photosPaths = list(glob.glob('./photos/*.png'))
#photos = np.stack([cv2.imread(str(x), cv2.IMREAD_GRAYSCALE)  for x in photosPaths])
photos = np.stack([cv2.imread(str(x), cv2.IMREAD_GRAYSCALE) 
                   for x in photosPaths2])
#display 3 images to see if it works...
#for image_path in photos[:3] :
  #  display.display(Image.open(str(image_path)))
#print(data_dir)

data=[]
for imgPath in photosPaths2:

	#Read the image into a numpy array using opencv
	#all the read images are of different shapes
	image = cv2.imread(imgPath)

	#resize the image to be 1400x1400 pixels (ignoring aspect ratio)

	image = cv2.resize(image, (1400, 1400))

	#flatten the images
	image_flatten = image.flatten()

	#Append each image data 1D array to the data list
	data.append(image_flatten)

# scale the raw pixel intensities to the range [0, 1]

# Shuffle the data
#shuffled_images = []
#while data:
#    i = random.randrange(len(data))
#    shuffled_images.append(data[i].reshape(1400,1400))
#    del data[i]

#photos = np.ndarray(shape=(len(suffled_img),3, 1400, 1400), dtype=np.float32)
#photos = np.array(shuffled_images[:])

#train_datagen = ImageDataGenerator(rescale=1./255)
#train_generator = train_datagen.flow_from_directory(
#    directory=r"a3_face_dataset/",
#    target_size=(1400,1400),
#    color_mode="rgb",
#    batch_size=32,
#    class_mode="binary",
#    shuffle=True,
#    seed=123
#)

# create autoencoder model
def encoder(input_img):
    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
    conv1 = BatchNormalization()(conv1)
    conv1 = Conv2D(32, (3,3), activation='relu', padding='same')(conv1)
    conv1 = BatchNormalization()(conv1)
    conv1 = Conv2D(32, (3,3), activation='relu', padding='same')(conv1)
    conv1 = BatchNormalization()(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = BatchNormalization()(conv2)
    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)
    conv2 = BatchNormalization()(conv2)
    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)
    conv2 = BatchNormalization()(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)
    conv3 = BatchNormalization()(conv3)
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)
    conv3 = BatchNormalization()(conv3)
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)
    conv3 = BatchNormalization()(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)
    conv4 = BatchNormalization()(conv4)
    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)
    conv4 = BatchNormalization()(conv4)
    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)
    conv4 = BatchNormalization()(conv4)
    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)
    conv5 = BatchNormalization()(conv5)
    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)
    conv5 = BatchNormalization()(conv5)
    conv5 = Conv2D(512, (3, 3), activation='sigmoid', padding='same')(conv5)
    conv5 = BatchNormalization()(conv5)
    return conv5,conv4,conv3,conv2,conv1

def decoder(conv5,conv4,conv3,conv2,conv1):
    up6 = merge([conv5, conv4], mode='concat', concat_axis=3)
    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)
    conv6 = BatchNormalization()(conv6)
    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)
    conv6 = BatchNormalization()(conv6)
    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)
    conv6 = BatchNormalization()(conv6)
    up7 = UpSampling2D((2,2))(conv6)
    up7 = merge([up7, conv3], mode='concat', concat_axis=3)
    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)
    conv7 = BatchNormalization()(conv7)
    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)
    conv7 = BatchNormalization()(conv7)
    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)
    conv7 = BatchNormalization()(conv7)
    up8 = UpSampling2D((2,2))(conv7)
    up8 = merge([up8, conv2], mode='concat', concat_axis=3)
    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)
    conv8 = BatchNormalization()(conv8)
    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)
    conv8 = BatchNormalization()(conv8)
    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)
    conv8 = BatchNormalization()(conv8)
    up9 = UpSampling2D((2,2))(conv8)
    up9 = merge([up9, conv1], mode='concat', concat_axis=3)
    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)
    conv9 = BatchNormalization()(conv9)
    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)
    conv9 = BatchNormalization()(conv9)
    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)
    conv9 = BatchNormalization()(conv9)
    decoded_1 = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(conv9)
    return decoded

"""*   Dataset preparation
*   Shuffle the dataset
* Create a noisy dataset
* Use the loss function
"""

conv5,conv4,conv3,conv2,conv1 = encoder(data)
autoencoder = Model(input_img, decoder(conv5,conv4,conv3,conv2,conv1))
#autoencoder.compile(loss=   , optimizer = RMSprop())

autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop())

noise_factor = 0.5
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) 
x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) 

x_train_noisy = np.clip(x_train_noisy, 0., 1.)
x_test_noisy = np.clip(x_test_noisy, 0., 1.)

autoencoder.fit(x_train_noisy, x_train,
                epochs=100,
                batch_size=128,
                shuffle=True,
                validation_data=(x_test_noisy, x_test),
                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])